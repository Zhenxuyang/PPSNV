{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('ml': virtualenvwrapper)"
  },
  "metadata": {
   "interpreter": {
    "hash": "a5ba3b76034c7efd269233736b10220d5b6e6d9d6bdf3361a98c45210b1ea0de"
   }
  },
  "interpreter": {
   "hash": "e58d3b4a238b69da25db37debc8e7c035df90db97ecce5d5d0275e11224d75ee"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读文献数据，分别存起来\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "raw_data_file = \"..\\data\\humu22768-sup-0001-suppmat\\humu22768-sup-0002-data.xlsx\"\n",
    "df = pd.read_excel(raw_data_file, index_col=0, sheet_name = None, usecols=[\"CHR\", \"Nuc-Pos\", \"REF-Nuc\", \"ALT-Nuc\"], engine=\"openpyxl\")\n",
    "\n",
    "variant_file_dir = \"..\\data\\\\variant\"\n",
    "if not os.path.exists(variant_file_dir):\n",
    "    os.mkdir(variant_file_dir)\n",
    "for key in df.keys():\n",
    "        _ = df[key]\n",
    "        _.to_csv(os.path.join(variant_file_dir, \"{}.csv\".format(key)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 把snp提取到vcf文件中\n",
    "import pandas \n",
    "import os\n",
    "\n",
    "variant_files_dir = \"../data/variant\"\n",
    "output_dir = \"../data/variant\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "print(\"starting\")\n",
    "for root, dirs, files in os.walk(variant_files_dir):\n",
    "    for file_ in files:\n",
    "        path = os.path.join(root, file_)\n",
    "        print(\"process {}\".format(path))\n",
    "        df_variants = pandas.read_csv(path, index_col=0)\n",
    "        print(list(df_variants))\n",
    "        output_file = file_.split(\".\")[0] + \".vcf\"\n",
    "        if output_file is None:\n",
    "            output_file = str(uuid.uuid4())\n",
    "        output = os.path.join(output_dir, output_file)\n",
    "        with open(output, \"w+\") as f:\n",
    "            f.write(\"##fileformat=VCFv4.3\\n\")\n",
    "            f.write(\"#CHROM\\tPOS\\tID\\tREF\\tALT\\tQUAL\\tFILTER\\tINFO\\n\")\n",
    "            for index, row in df_variants.iterrows():\n",
    "                chr = index\n",
    "                pos = row[\"Nuc-Pos\"]\n",
    "                ref = row[\"REF-Nuc\"]\n",
    "                alt = row[\"ALT-Nuc\"]\n",
    "                f.write(\"{}\\t{}\\t.\\t{}\\t{}\\t.\\t.\\t.\\n\".format(chr, pos, ref, alt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查annovar的注册结果\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def annovar_res_visualize(exo_df):\n",
    "    cols = list(exo_df)\n",
    "    stats = [[] for _ in range(3)]\n",
    "    for col in cols:\n",
    "        stats[0].append((exo_df[col]==\".\").sum())\n",
    "        stats[1].append((exo_df[col]!=\".\").sum())\n",
    "        stats[2].append(col)\n",
    "\n",
    "    plt.figure(figsize=(80, 8))\n",
    "    plt.xticks(rotation=45)\n",
    "    size = 5\n",
    "    plt.bar(range(len(cols)), stats[0], label=\"NaN\", tick_label=stats[2])\n",
    "    plt\n",
    "    plt.bar(range(len(cols)), stats[1], label=\"Non-NaN\", bottom = stats[0])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "dir_ = \"../data/variant\"\n",
    "for root, dirs, files in os.walk(dir_):\n",
    "    for f in files:\n",
    "        if f.split(\".\")[-1] == \"txt\":\n",
    "            file_path = os.path.join(\"../data/variant\", f)\n",
    "            df = pd.read_table(file_path).iloc[:,:-11]\n",
    "            df.to_csv(os.path.join(\"../data/variant\", \".\".join(f.split(\".\")[:-1]) + \".csv\"), index=0)\n",
    "            annovar_res_visualize(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "datasets = ['HumVarFiltered', 'ExoVarFiltered', 'VariBenchSelected', 'predictSNPSelected', 'SwissVarSelected']\n",
    "# datasets = ['HumVarFiltered']\n",
    "dir_ = \"../data/variant\"\n",
    "out_dir_ = \"../data/variants_selected/\"\n",
    "dfs = []\n",
    "keys = ['True Label', 'Chr', 'Start', 'End', 'Ref', 'Alt', 'Func.refGene', 'Gene.refGene', 'GeneDetail.refGene', 'ExonicFunc.refGene', 'AAChange.refGene', 'Func.knownGene', 'Gene.knownGene', 'GeneDetail.knownGene', 'ExonicFunc.knownGene', 'AAChange.knownGene', 'Func.ensGene', 'Gene.ensGene', 'GeneDetail.ensGene', 'ExonicFunc.ensGene', 'AAChange.ensGene', 'SIFT_score', 'SIFT_pred', 'Polyphen2_HDIV_score', 'Polyphen2_HDIV_pred', 'Polyphen2_HVAR_score', 'Polyphen2_HVAR_pred', 'LRT_score', 'LRT_pred', 'MutationTaster_score', 'MutationTaster_pred', 'MutationAssessor_score', 'MutationAssessor_pred', 'FATHMM_score', 'FATHMM_pred', 'RadialSVM_score', 'RadialSVM_pred', 'LR_score', 'LR_pred', 'VEST3_score', 'CADD_raw', 'CADD_phred', 'GERP++_RS', 'phyloP46way_placental', 'phyloP100way_vertebrate', 'SiPhy_29way_logOdds', 'Alt.1', '#Chr', 'Start.1', 'DamagePredCount', 'SIFT_pred.1', 'SIFT4G_pred', 'LRT_pred.1', 'MutationTaster_pred.1', 'MutationAssessor_pred.1', 'FATHMM_pred.1', 'PROVEAN_pred', 'MetaSVM_pred', 'MetaLR_pred', 'M-CAP_pred', 'MutPred_score', 'MVP_score', 'MPC_score', 'PrimateAI_pred', 'DEOGEN2_pred', 'BayesDel_addAF_pred', 'BayesDel_noAF_pred', 'LIST-S2_pred', 'DANN_score', 'fathmm-MKL_coding_pred', 'fathmm-XF_coding_pred', 'Eigen-raw_coding', 'Eigen-phred_coding', 'Eigen-PC-raw_coding', 'Eigen-PC-phred_coding', 'integrated_fitCons_score', 'GM12878_fitCons_score', 'H1-hESC_fitCons_score', 'HUVEC_fitCons_score', 'GERP++_NR', 'GERP++_RS.1', 'phyloP100way_vertebrate.1', 'phyloP30way_mammalian', 'phyloP17way_primate', 'phastCons100way_vertebrate', 'phastCons30way_mammalian', 'phastCons17way_primate', 'bStatistic', 'Interpro_domain', 'GTEx_V8_gene', 'GTEx_V8_tissue', 'ExAC_ALL', 'ExAC_AFR', 'ExAC_AMR', 'ExAC_EAS', 'ExAC_FIN', 'ExAC_NFE', 'ExAC_OTH', 'ExAC_SAS', 'MCAP', 'REVEL', 'CLNALLELEID', 'CLNDN', 'CLNDISDB', 'CLNREVSTAT', 'CLNSIG', 'cytoBand', 'avsnp147']\n",
    "for dataset in datasets:\n",
    "    df = pd.read_csv(os.path.join(dir_, dataset + \".hg19_multianno.csv\"))\n",
    "    df = df[~(df==\".\")]\n",
    "    count = df.count()\n",
    "    total = df.shape[0]\n",
    "    reserved = []\n",
    "    for key in keys:\n",
    "        if count[key] / total > 0.8:\n",
    "            if key not in reserved:\n",
    "                reserved.append(key)\n",
    "not_reserved = list(set(keys)-set(reserved))\n",
    "for dataset in datasets:\n",
    "    df = pd.read_csv(os.path.join(dir_, dataset + \".hg19_multianno.csv\"))\n",
    "    df = df[~(df==\".\")]\n",
    "    df = df.drop(not_reserved, axis=1)\n",
    "    df.to_csv(os.path.join(out_dir_, dataset + \".selected.hg19_multianno.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# 训练数据中包含的特征\n",
    "features = ['True Label', 'Chr', 'Start', 'End', 'Ref', 'Alt', 'AAChange.refGene', 'SIFT_score', 'Polyphen2_HDIV_score', 'Polyphen2_HVAR_score', 'LRT_score', 'MutationTaster_score', 'MutationAssessor_score', 'FATHMM_score', 'RadialSVM_score', 'LR_score', 'VEST3_score', 'CADD_phred']\n",
    "# 原始数据文件目录\n",
    "raw_data_dir = '../data/variant/grimm_annovar_annotated'\n",
    "flitered_data_output_dir = 'fliter'\n",
    "if not os.path.exists(flitered_data_output_dir):\n",
    "    os.mkdir(flitered_data_output_dir)\n",
    "# 合法染色体\n",
    "chrs = []\n",
    "for i in range(1, 23):\n",
    "    chrs.append(str(i))\n",
    "chrs.append(\"X\")\n",
    "chrs.append(\"Y\")\n",
    "\n",
    "\n",
    "# 从转录本提取氨基酸突变。eg LOXL4:NM_032211:exon3:c.C406A:p.R136S， aa_ref为R， aa_alt为S\n",
    "def split_transcript(row):\n",
    "    trans = row[\"AAChange.refGene\"]\n",
    "    trans = trans.split(\",\")\n",
    "    # first\n",
    "    tran = trans[0]\n",
    "    aachange = tran.split(\":\")\n",
    "    _ = aachange[-1].split(\".\")[-1]\n",
    "    aa_ref = _[0]\n",
    "    aa_alt = _[-1]\n",
    "    return aa_ref, aa_alt\n",
    "\n",
    "\n",
    "for dir_, _, filenames in os.walk(raw_data_dir):\n",
    "    for filename in filenames:\n",
    "        print(\"processing {}\".format(filename))\n",
    "        df = pd.read_csv(os.path.join(raw_data_dir, filename))\n",
    "        # df = df[features]\n",
    "        # .置空\n",
    "        df = df[~(df == '.')]\n",
    "        # # 剔除非法染色体\n",
    "        df[\"Chr\"] = df[\"Chr\"].astype(\"str\")\n",
    "        if filename == \"predictSNPSelected.hg19_multianno.csv\" or filename == \"SwissVarSelected.hg19_multianno.csv\":\n",
    "            df[[\"Chr\"]] = df.apply(lambda x: x[\"Chr\"][3:], axis=1)\n",
    "        df = df[(df[\"Chr\"].isin(chrs))]\n",
    "        # 处理氨基酸突变序列\n",
    "        df = df[~(df[\"AAChange.refGene\"].isnull())]\n",
    "        # tmp = df.apply(split_transcript, axis=1, result_type=\"expand\")\n",
    "        df[[\"A_Ref\", \"A_Alt\"]] = df.apply(split_transcript, axis=1, result_type=\"expand\")\n",
    "        df = df.drop([\"AAChange.refGene\"], axis=1)\n",
    "        # 类型转换\n",
    "        df = df.astype(dtype={'True Label': object, \"SIFT_score\": float, \"Polyphen2_HDIV_score\": float, \"Polyphen2_HVAR_score\": float, \"LRT_score\": float, \"MutationTaster_score\":float, \"MutationAssessor_score\": float, \"FATHMM_score\":float, \"RadialSVM_score\":float, \"LR_score\": float, \"VEST3_score\":float, \"CADD_phred\":float})\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        df['Chr'] = lbl.fit_transform(df['Chr'].astype(str))\n",
    "        df['Ref'] = lbl.fit_transform(df['Ref'].astype(str))\n",
    "        df['Alt'] = lbl.fit_transform(df['Alt'].astype(str))\n",
    "        df['A_Ref'] = lbl.fit_transform(df['A_Ref'].astype(str))\n",
    "        df['A_Alt'] = lbl.fit_transform(df['A_Alt'].astype(str))\n",
    "        df[\"True Label\"].replace(-1, 0, inplace=True)\n",
    "        df.to_csv(os.path.join(flitered_data_output_dir, \"flitered_{}\".format(filename)), index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去重\n",
    "import pandas as pd\n",
    "\n",
    "dfs = {}\n",
    "input_dir = \"filter\"\n",
    "for root, _, files in os.walk(input_dir):\n",
    "    for file_ in files:\n",
    "        dataset = file_.split(\".\")[0]\n",
    "        print(dataset)\n",
    "        df = pd.read_csv(os.path.join(root, file_))\n",
    "        dfs[dataset] = df\n",
    "\n",
    "print(df.keys())\n",
    "datasets = ['ExoVarFiltered', 'HumVarFiltered', 'predictSNPSelected', 'SwissVarSelected', 'VariBenchSelected']\n",
    "\n",
    "# exo,humvar,predicted,varibench四个数据集合并去重，swissvar作为验证\n",
    "df = pd.concat([dfs['ExoVarFiltered'], dfs['HumVarFiltered'], dfs['predictSNPSelected'], dfs['VariBenchSelected']])\n",
    "print(df.shape)\n",
    "df.drop_duplicates(subset=['Chr', 'Start', 'End', 'Ref', 'Alt'], inplace=True)\n",
    "print(df.shape)\n",
    "\n",
    "df.to_csv('filter/merged.csv', index=False)\n",
    "\n",
    "pd.merge(df, dfs['SwissVarSelected'], on=['Chr', 'Start', 'End', 'Ref', 'Alt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dataframe_image as dfi\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Dataset\", \"Deleterious variants (D)\", \"Neutral variants (N)\", \"Total\", \"Description\"])\n",
    "d1 = [\"HumVar\", 21090, 19299, 40389, \"Mendelian disease variant identification\"]\n",
    "d2 = [\"ExoVar\", 5156, 3694, 8850, \"Dataset composed of pathogenic nsSNVs and nearly nonpathogenic rare nsSNVs\"]\n",
    "d3 = [\"VariBenchSelected\", 4309, 5957, 10266, \"Variation datasets affecting protein tolerance\"]\n",
    "d4 = [\"predictSNPSelected\", 10000, 6098, 16098, \"Benchmark dataset used for the evaluation of…prediction tools and training of consensus classifier PredictSNP\"]\n",
    "d5 = [\"SwissVarSelected\", 4526, 8203, 12729, \"Comprehensive collection of single amino acid polymorphisms (SAPs) and diseases in the UniProtKB/Swiss-Prot knowledgebase\"]\n",
    "df.loc[0] = d1\n",
    "df.loc[1] = d2\n",
    "df.loc[2] = d3\n",
    "df.loc[3] = d4\n",
    "df.loc[4] = d5\n",
    "styled = df.style\n",
    "styled.set_table_styles([{'selector': 'td', 'props':[('text-align', 'left')]}, {'selector': 'th', 'props':[('text-align', 'left')]}])\n",
    "# styled.render()\n",
    "dfi.export(styled, \"raw_count.png\", fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}