{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('ml': virtualenvwrapper)"
  },
  "metadata": {
   "interpreter": {
    "hash": "a5ba3b76034c7efd269233736b10220d5b6e6d9d6bdf3361a98c45210b1ea0de"
   }
  },
  "interpreter": {
   "hash": "e58d3b4a238b69da25db37debc8e7c035df90db97ecce5d5d0275e11224d75ee"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读文献数据，分别存起来\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "raw_data_file = \"..\\data\\humu22768-sup-0001-suppmat\\humu22768-sup-0002-data.xlsx\"\n",
    "df = pd.read_excel(raw_data_file, index_col=0, sheet_name = None, usecols=[\"CHR\", \"Nuc-Pos\", \"REF-Nuc\", \"ALT-Nuc\"], engine=\"openpyxl\")\n",
    "\n",
    "variant_file_dir = \"..\\data\\\\variant\"\n",
    "if not os.path.exists(variant_file_dir):\n",
    "    os.mkdir(variant_file_dir)\n",
    "for key in df.keys():\n",
    "        _ = df[key]\n",
    "        _.to_csv(os.path.join(variant_file_dir, \"{}.csv\".format(key)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 把snp提取到vcf文件中\n",
    "import pandas \n",
    "import os\n",
    "\n",
    "variant_files_dir = \"../data/variant\"\n",
    "output_dir = \"../data/variant\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "print(\"starting\")\n",
    "for root, dirs, files in os.walk(variant_files_dir):\n",
    "    for file_ in files:\n",
    "        path = os.path.join(root, file_)\n",
    "        print(\"process {}\".format(path))\n",
    "        df_variants = pandas.read_csv(path, index_col=0)\n",
    "        print(list(df_variants))\n",
    "        output_file = file_.split(\".\")[0] + \".vcf\"\n",
    "        if output_file is None:\n",
    "            output_file = str(uuid.uuid4())\n",
    "        output = os.path.join(output_dir, output_file)\n",
    "        with open(output, \"w+\") as f:\n",
    "            f.write(\"##fileformat=VCFv4.3\\n\")\n",
    "            f.write(\"#CHROM\\tPOS\\tID\\tREF\\tALT\\tQUAL\\tFILTER\\tINFO\\n\")\n",
    "            for index, row in df_variants.iterrows():\n",
    "                chr = index\n",
    "                pos = row[\"Nuc-Pos\"]\n",
    "                ref = row[\"REF-Nuc\"]\n",
    "                alt = row[\"ALT-Nuc\"]\n",
    "                f.write(\"{}\\t{}\\t.\\t{}\\t{}\\t.\\t.\\t.\\n\".format(chr, pos, ref, alt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查annovar的注册结果\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def annovar_res_visualize(exo_df):\n",
    "    cols = list(exo_df)\n",
    "    stats = [[] for _ in range(3)]\n",
    "    for col in cols:\n",
    "        stats[0].append((exo_df[col]==\".\").sum())\n",
    "        stats[1].append((exo_df[col]!=\".\").sum())\n",
    "        stats[2].append(col)\n",
    "\n",
    "    plt.figure(figsize=(80, 8))\n",
    "    plt.xticks(rotation=45)\n",
    "    size = 5\n",
    "    plt.bar(range(len(cols)), stats[0], label=\"NaN\", tick_label=stats[2])\n",
    "    plt\n",
    "    plt.bar(range(len(cols)), stats[1], label=\"Non-NaN\", bottom = stats[0])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "dir_ = \"../data/variant\"\n",
    "for root, dirs, files in os.walk(dir_):\n",
    "    for f in files:\n",
    "        if f.split(\".\")[-1] == \"txt\":\n",
    "            file_path = os.path.join(\"../data/variant\", f)\n",
    "            df = pd.read_table(file_path).iloc[:,:-11]\n",
    "            df.to_csv(os.path.join(\"../data/variant\", \".\".join(f.split(\".\")[:-1]) + \".csv\"), index=0)\n",
    "            annovar_res_visualize(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "datasets = ['HumVarFiltered', 'ExoVarFiltered', 'VariBenchSelected', 'predictSNPSelected', 'SwissVarSelected']\n",
    "# datasets = ['HumVarFiltered']\n",
    "dir_ = \"../data/variant\"\n",
    "out_dir_ = \"../data/variants_selected/\"\n",
    "dfs = []\n",
    "keys = ['True Label', 'Chr', 'Start', 'End', 'Ref', 'Alt', 'Func.refGene', 'Gene.refGene', 'GeneDetail.refGene', 'ExonicFunc.refGene', 'AAChange.refGene', 'Func.knownGene', 'Gene.knownGene', 'GeneDetail.knownGene', 'ExonicFunc.knownGene', 'AAChange.knownGene', 'Func.ensGene', 'Gene.ensGene', 'GeneDetail.ensGene', 'ExonicFunc.ensGene', 'AAChange.ensGene', 'SIFT_score', 'SIFT_pred', 'Polyphen2_HDIV_score', 'Polyphen2_HDIV_pred', 'Polyphen2_HVAR_score', 'Polyphen2_HVAR_pred', 'LRT_score', 'LRT_pred', 'MutationTaster_score', 'MutationTaster_pred', 'MutationAssessor_score', 'MutationAssessor_pred', 'FATHMM_score', 'FATHMM_pred', 'RadialSVM_score', 'RadialSVM_pred', 'LR_score', 'LR_pred', 'VEST3_score', 'CADD_raw', 'CADD_phred', 'GERP++_RS', 'phyloP46way_placental', 'phyloP100way_vertebrate', 'SiPhy_29way_logOdds', 'Alt.1', '#Chr', 'Start.1', 'DamagePredCount', 'SIFT_pred.1', 'SIFT4G_pred', 'LRT_pred.1', 'MutationTaster_pred.1', 'MutationAssessor_pred.1', 'FATHMM_pred.1', 'PROVEAN_pred', 'MetaSVM_pred', 'MetaLR_pred', 'M-CAP_pred', 'MutPred_score', 'MVP_score', 'MPC_score', 'PrimateAI_pred', 'DEOGEN2_pred', 'BayesDel_addAF_pred', 'BayesDel_noAF_pred', 'LIST-S2_pred', 'DANN_score', 'fathmm-MKL_coding_pred', 'fathmm-XF_coding_pred', 'Eigen-raw_coding', 'Eigen-phred_coding', 'Eigen-PC-raw_coding', 'Eigen-PC-phred_coding', 'integrated_fitCons_score', 'GM12878_fitCons_score', 'H1-hESC_fitCons_score', 'HUVEC_fitCons_score', 'GERP++_NR', 'GERP++_RS.1', 'phyloP100way_vertebrate.1', 'phyloP30way_mammalian', 'phyloP17way_primate', 'phastCons100way_vertebrate', 'phastCons30way_mammalian', 'phastCons17way_primate', 'bStatistic', 'Interpro_domain', 'GTEx_V8_gene', 'GTEx_V8_tissue', 'ExAC_ALL', 'ExAC_AFR', 'ExAC_AMR', 'ExAC_EAS', 'ExAC_FIN', 'ExAC_NFE', 'ExAC_OTH', 'ExAC_SAS', 'MCAP', 'REVEL', 'CLNALLELEID', 'CLNDN', 'CLNDISDB', 'CLNREVSTAT', 'CLNSIG', 'cytoBand', 'avsnp147']\n",
    "for dataset in datasets:\n",
    "    df = pd.read_csv(os.path.join(dir_, dataset + \".hg19_multianno.csv\"))\n",
    "    df = df[~(df==\".\")]\n",
    "    count = df.count()\n",
    "    total = df.shape[0]\n",
    "    reserved = []\n",
    "    for key in keys:\n",
    "        if count[key] / total > 0.8:\n",
    "            if key not in reserved:\n",
    "                reserved.append(key)\n",
    "not_reserved = list(set(keys)-set(reserved))\n",
    "for dataset in datasets:\n",
    "    df = pd.read_csv(os.path.join(dir_, dataset + \".hg19_multianno.csv\"))\n",
    "    df = df[~(df==\".\")]\n",
    "    df = df.drop(not_reserved, axis=1)\n",
    "    df.to_csv(os.path.join(out_dir_, dataset + \".selected.hg19_multianno.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# 训练数据中包含的特征\n",
    "features = ['True Label', 'Chr', 'Start', 'End', 'Ref', 'Alt', 'AAChange.refGene', 'SIFT_score', 'Polyphen2_HDIV_score', 'Polyphen2_HVAR_score', 'LRT_score', 'MutationTaster_score', 'MutationAssessor_score', 'FATHMM_score', 'RadialSVM_score', 'LR_score', 'VEST3_score', 'CADD_phred']\n",
    "# 原始数据文件目录\n",
    "raw_data_dir = '../data/variant/grimm_annovar_annotated'\n",
    "flitered_data_output_dir = 'fliter'\n",
    "if not os.path.exists(flitered_data_output_dir):\n",
    "    os.mkdir(flitered_data_output_dir)\n",
    "# 合法染色体\n",
    "chrs = []\n",
    "for i in range(1, 23):\n",
    "    chrs.append(str(i))\n",
    "chrs.append(\"X\")\n",
    "chrs.append(\"Y\")\n",
    "\n",
    "\n",
    "# 从转录本提取氨基酸突变。eg LOXL4:NM_032211:exon3:c.C406A:p.R136S， aa_ref为R， aa_alt为S\n",
    "def split_transcript(row):\n",
    "    trans = row[\"AAChange.refGene\"]\n",
    "    trans = trans.split(\",\")\n",
    "    # first\n",
    "    tran = trans[0]\n",
    "    aachange = tran.split(\":\")\n",
    "    _ = aachange[-1].split(\".\")[-1]\n",
    "    aa_ref = _[0]\n",
    "    aa_alt = _[-1]\n",
    "    return aa_ref, aa_alt\n",
    "\n",
    "\n",
    "for dir_, _, filenames in os.walk(raw_data_dir):\n",
    "    for filename in filenames:\n",
    "        print(\"processing {}\".format(filename))\n",
    "        df = pd.read_csv(os.path.join(raw_data_dir, filename))\n",
    "        # df = df[features]\n",
    "        # .置空\n",
    "        df = df[~(df == '.')]\n",
    "        # # 剔除非法染色体\n",
    "        df[\"Chr\"] = df[\"Chr\"].astype(\"str\")\n",
    "        if filename == \"predictSNPSelected.hg19_multianno.csv\" or filename == \"SwissVarSelected.hg19_multianno.csv\":\n",
    "            df[[\"Chr\"]] = df.apply(lambda x: x[\"Chr\"][3:], axis=1)\n",
    "        df = df[(df[\"Chr\"].isin(chrs))]\n",
    "        # 处理氨基酸突变序列\n",
    "        df = df[~(df[\"AAChange.refGene\"].isnull())]\n",
    "        # tmp = df.apply(split_transcript, axis=1, result_type=\"expand\")\n",
    "        df[[\"A_Ref\", \"A_Alt\"]] = df.apply(split_transcript, axis=1, result_type=\"expand\")\n",
    "        df = df.drop([\"AAChange.refGene\"], axis=1)\n",
    "        # 类型转换\n",
    "        df = df.astype(dtype={'True Label': object, \"SIFT_score\": float, \"Polyphen2_HDIV_score\": float, \"Polyphen2_HVAR_score\": float, \"LRT_score\": float, \"MutationTaster_score\":float, \"MutationAssessor_score\": float, \"FATHMM_score\":float, \"RadialSVM_score\":float, \"LR_score\": float, \"VEST3_score\":float, \"CADD_phred\":float})\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        df['Chr'] = lbl.fit_transform(df['Chr'].astype(str))\n",
    "        df['Ref'] = lbl.fit_transform(df['Ref'].astype(str))\n",
    "        df['Alt'] = lbl.fit_transform(df['Alt'].astype(str))\n",
    "        df['A_Ref'] = lbl.fit_transform(df['A_Ref'].astype(str))\n",
    "        df['A_Alt'] = lbl.fit_transform(df['A_Alt'].astype(str))\n",
    "        df[\"True Label\"].replace(-1, 0, inplace=True)\n",
    "        df.to_csv(os.path.join(flitered_data_output_dir, \"flitered_{}\".format(filename)), index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去重\n",
    "import pandas as pd\n",
    "\n",
    "dfs = {}\n",
    "input_dir = \"filter\"\n",
    "for root, _, files in os.walk(input_dir):\n",
    "    for file_ in files:\n",
    "        dataset = file_.split(\".\")[0]\n",
    "        print(dataset)\n",
    "        df = pd.read_csv(os.path.join(root, file_))\n",
    "        dfs[dataset] = df\n",
    "\n",
    "datasets = ['ExoVarFiltered', 'HumVarFiltered', 'predictSNPSelected', 'SwissVarSelected', 'VariBenchSelected']\n",
    "# exo,humvar,predicted,varibench四个数据集合并去重，swissvar作为验证\n",
    "df = pd.concat([dfs['ExoVarFiltered'], dfs['HumVarFiltered'], dfs['predictSNPSelected'], dfs['VariBenchSelected']])\n",
    "print(df.shape)\n",
    "df.drop_duplicates(subset=['Chr', 'Start', 'End', 'Ref', 'Alt'], inplace=True)\n",
    "print(df.shape)\n",
    "\n",
    "df.to_csv('filter/merged.csv', index=False)\n",
    "\n",
    "pd.merge(df, dfs['SwissVarSelected'], on=['Chr', 'Start', 'End', 'Ref', 'Alt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ExoVarFiltered\n",
      "HumVarFiltered\n",
      "E:\\Envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3147: DtypeWarning: Columns (17,69) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "E:\\Envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3147: DtypeWarning: Columns (46,59) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "merged\n",
      "E:\\Envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3147: DtypeWarning: Columns (8,46,59) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "merged_with_labels\n",
      "merge_with_labels\n",
      "predictSNPSelected\n",
      "SwissVarSelected\n",
      "swissvar_with_labels\n",
      "VariBenchSelected\n",
      "E:\\Envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3147: DtypeWarning: Columns (46) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "(66577, 109)\n",
      "(66577, 109)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [True Label_x, Chr, Start, End, Ref, Alt, Func.refGene_x, Gene.refGene_x, GeneDetail.refGene_x, ExonicFunc.refGene_x, Func.knownGene_x, Gene.knownGene_x, GeneDetail.knownGene_x, ExonicFunc.knownGene_x, AAChange.knownGene_x, Func.ensGene_x, Gene.ensGene_x, GeneDetail.ensGene_x, ExonicFunc.ensGene_x, AAChange.ensGene_x, SIFT_score_x, SIFT_pred_x, Polyphen2_HDIV_score_x, Polyphen2_HDIV_pred_x, Polyphen2_HVAR_score_x, Polyphen2_HVAR_pred_x, LRT_score_x, LRT_pred_x, MutationTaster_score_x, MutationTaster_pred_x, MutationAssessor_score_x, MutationAssessor_pred_x, FATHMM_score_x, FATHMM_pred_x, RadialSVM_score_x, RadialSVM_pred_x, LR_score_x, LR_pred_x, VEST3_score_x, CADD_raw_x, CADD_phred_x, GERP++_RS_x, phyloP46way_placental_x, phyloP100way_vertebrate_x, SiPhy_29way_logOdds_x, Alt.1_x, #Chr_x, Start.1_x, DamagePredCount_x, SIFT_pred.1_x, SIFT4G_pred_x, LRT_pred.1_x, MutationTaster_pred.1_x, MutationAssessor_pred.1_x, FATHMM_pred.1_x, PROVEAN_pred_x, MetaSVM_pred_x, MetaLR_pred_x, M-CAP_pred_x, MutPred_score_x, MVP_score_x, MPC_score_x, PrimateAI_pred_x, DEOGEN2_pred_x, BayesDel_addAF_pred_x, BayesDel_noAF_pred_x, LIST-S2_pred_x, DANN_score_x, fathmm-MKL_coding_pred_x, fathmm-XF_coding_pred_x, Eigen-raw_coding_x, Eigen-phred_coding_x, Eigen-PC-raw_coding_x, Eigen-PC-phred_coding_x, integrated_fitCons_score_x, GM12878_fitCons_score_x, H1-hESC_fitCons_score_x, HUVEC_fitCons_score_x, GERP++_NR_x, GERP++_RS.1_x, phyloP100way_vertebrate.1_x, phyloP30way_mammalian_x, phyloP17way_primate_x, phastCons100way_vertebrate_x, phastCons30way_mammalian_x, phastCons17way_primate_x, bStatistic_x, Interpro_domain_x, GTEx_V8_gene_x, GTEx_V8_tissue_x, ExAC_ALL_x, ExAC_AFR_x, ExAC_AMR_x, ExAC_EAS_x, ExAC_FIN_x, ExAC_NFE_x, ExAC_OTH_x, ExAC_SAS_x, MCAP_x, REVEL_x, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 213 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>True Label_x</th>\n      <th>Chr</th>\n      <th>Start</th>\n      <th>End</th>\n      <th>Ref</th>\n      <th>Alt</th>\n      <th>Func.refGene_x</th>\n      <th>Gene.refGene_x</th>\n      <th>GeneDetail.refGene_x</th>\n      <th>ExonicFunc.refGene_x</th>\n      <th>...</th>\n      <th>REVEL_y</th>\n      <th>CLNALLELEID_y</th>\n      <th>CLNDN_y</th>\n      <th>CLNDISDB_y</th>\n      <th>CLNREVSTAT_y</th>\n      <th>CLNSIG_y</th>\n      <th>cytoBand_y</th>\n      <th>avsnp147_y</th>\n      <th>A_Ref_y</th>\n      <th>A_Alt_y</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n<p>0 rows × 213 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# 去重\n",
    "import pandas as pd\n",
    "\n",
    "dfs = {}\n",
    "input_dir = \"filter\"\n",
    "for root, _, files in os.walk(input_dir):\n",
    "    for file_ in files:\n",
    "        dataset = file_.split(\".\")[0]\n",
    "        print(dataset)\n",
    "        df = pd.read_csv(os.path.join(root, file_))\n",
    "        dfs[dataset] = df\n",
    "\n",
    "# datasets = ['ExoVarFiltered', 'HumVarFiltered', 'predictSNPSelected', 'SwissVarSelected', 'VariBenchSelected']\n",
    "datasets = ['ExoVarFiltered', 'HumVarFiltered', 'predictSNPSelected', 'SwissVarSelected', 'VariBenchSelected']\n",
    "# exo,humvar,predicted,varibench四个数据集合并去重，swissvar作为验证\n",
    "# df = pd.concat([dfs['ExoVarFiltered'], dfs['HumVarFiltered'], dfs['predictSNPSelected'], dfs['VariBenchSelected']])\n",
    "df = pd.concat([dfs['HumVarFiltered'], dfs['predictSNPSelected'], dfs['VariBenchSelected']])\n",
    "print(df.shape)\n",
    "df.drop_duplicates(subset=['Chr', 'Start', 'End', 'Ref', 'Alt'], inplace=True)\n",
    "print(df.shape)\n",
    "\n",
    "df.to_csv('filter/merged_hpv.csv', index=False)\n",
    "\n",
    "pd.merge(df, dfs['SwissVarSelected'], on=['Chr', 'Start', 'End', 'Ref', 'Alt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dataframe_image as dfi\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Dataset\", \"Deleterious variants (D)\", \"Neutral variants (N)\", \"Total\", \"Description\"])\n",
    "d1 = [\"HumVar\", 21090, 19299, 40389, \"Mendelian disease variant identification\"]\n",
    "d2 = [\"ExoVar\", 5156, 3694, 8850, \"Dataset composed of pathogenic nsSNVs and nearly nonpathogenic rare nsSNVs\"]\n",
    "d3 = [\"VariBenchSelected\", 4309, 5957, 10266, \"Variation datasets affecting protein tolerance\"]\n",
    "d4 = [\"predictSNPSelected\", 10000, 6098, 16098, \"Benchmark dataset used for the evaluation of…prediction tools and training of consensus classifier PredictSNP\"]\n",
    "d5 = [\"SwissVarSelected\", 4526, 8203, 12729, \"Comprehensive collection of single amino acid polymorphisms (SAPs) and diseases in the UniProtKB/Swiss-Prot knowledgebase\"]\n",
    "df.loc[0] = d1\n",
    "df.loc[1] = d2\n",
    "df.loc[2] = d3\n",
    "df.loc[3] = d4\n",
    "df.loc[4] = d5\n",
    "styled = df.style\n",
    "styled.set_table_styles([{'selector': 'td', 'props':[('text-align', 'left')]}, {'selector': 'th', 'props':[('text-align', 'left')]}])\n",
    "# styled.render()\n",
    "dfi.export(styled, \"raw_count.png\", fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}