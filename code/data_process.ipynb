{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('ml': virtualenv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "a5ba3b76034c7efd269233736b10220d5b6e6d9d6bdf3361a98c45210b1ea0de"
   }
  },
  "interpreter": {
   "hash": "e58d3b4a238b69da25db37debc8e7c035df90db97ecce5d5d0275e11224d75ee"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "save data of Grimm to individual csv"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import os\r\n",
    "\r\n",
    "raw_data_file = \"..\\data\\humu22768-sup-0001-suppmat\\humu22768-sup-0002-data.xlsx\"\r\n",
    "df = pd.read_excel(raw_data_file, index_col=0, sheet_name = None, usecols=[\"CHR\", \"Nuc-Pos\", \"REF-Nuc\", \"ALT-Nuc\"], engine=\"openpyxl\")\r\n",
    "\r\n",
    "variant_file_dir = \"..\\data\\\\variant\"\r\n",
    "if not os.path.exists(variant_file_dir):\r\n",
    "    os.mkdir(variant_file_dir)\r\n",
    "for key in df.keys():\r\n",
    "        _ = df[key]\r\n",
    "        _.to_csv(os.path.join(variant_file_dir, \"{}.csv\".format(key)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "convert csv to vcf for annotation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 把snp提取到vcf文件中\r\n",
    "import pandas \r\n",
    "import os\r\n",
    "\r\n",
    "variant_files_dir = \"../data/variant\"\r\n",
    "output_dir = \"../data/variant\"\r\n",
    "if not os.path.exists(output_dir):\r\n",
    "    os.mkdir(output_dir)\r\n",
    "print(\"starting\")\r\n",
    "for root, dirs, files in os.walk(variant_files_dir):\r\n",
    "    for file_ in files:\r\n",
    "        path = os.path.join(root, file_)\r\n",
    "        print(\"process {}\".format(path))\r\n",
    "        df_variants = pandas.read_csv(path, index_col=0)\r\n",
    "        print(list(df_variants))\r\n",
    "        output_file = file_.split(\".\")[0] + \".vcf\"\r\n",
    "        if output_file is None:\r\n",
    "            output_file = str(uuid.uuid4())\r\n",
    "        output = os.path.join(output_dir, output_file)\r\n",
    "        with open(output, \"w+\") as f:\r\n",
    "            f.write(\"##fileformat=VCFv4.3\\n\")\r\n",
    "            f.write(\"#CHROM\\tPOS\\tID\\tREF\\tALT\\tQUAL\\tFILTER\\tINFO\\n\")\r\n",
    "            for index, row in df_variants.iterrows():\r\n",
    "                chr = index\r\n",
    "                pos = row[\"Nuc-Pos\"]\r\n",
    "                ref = row[\"REF-Nuc\"]\r\n",
    "                alt = row[\"ALT-Nuc\"]\r\n",
    "                f.write(\"{}\\t{}\\t.\\t{}\\t{}\\t.\\t.\\t.\\n\".format(chr, pos, ref, alt))"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "process the output of Annovar"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from sklearn import preprocessing\r\n",
    "chr_lbl = preprocessing.LabelEncoder()\r\n",
    "chr_lbl.fit(['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '3',  '4', '5', '6', '7', '8', '9', 'X', 'Y'])\r\n",
    "\r\n",
    "amid_acid_lbl= preprocessing.LabelEncoder()\r\n",
    "amid_acid_lbl.fit(['A','C','D','E','F','G','H','I','K','L','M','N','P','Q','R','S','T','U', 'V','W','X','Y'])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def encode(row):\r\n",
    "    chr_ = row['Chr']\r\n",
    "    a_ref = row['A_Ref']\r\n",
    "    a_alt = row['A_Alt']\r\n",
    "    if chr_.startswith('chr'):\r\n",
    "        chr_ = chr_[3:]\r\n",
    "    try:\r\n",
    "        chr_encoded = chr_lbl.transform([chr_])\r\n",
    "    except ValueError:\r\n",
    "        chr_encoded = [None]\r\n",
    "    try:\r\n",
    "        a_ref_encoded = amid_acid_lbl.transform([a_ref])\r\n",
    "    except ValueError:\r\n",
    "        a_ref_encoded = [None]\r\n",
    "    try:\r\n",
    "        a_alt_encoded = amid_acid_lbl.transform([a_alt])\r\n",
    "    except ValueError:\r\n",
    "        a_alt_encoded = [None]\r\n",
    "    return chr_encoded[0], a_ref_encoded[0], a_alt_encoded[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 数据预处理\r\n",
    "import pandas as pd\r\n",
    "import os\r\n",
    "import numpy as np\r\n",
    "from sklearn import preprocessing\r\n",
    "\r\n",
    "# 训练数据中包含的特征\r\n",
    "features = ['True Label', 'Chr', 'Start', 'End', 'Ref', 'Alt', 'AAChange.refGene', 'SIFT_score', 'Polyphen2_HDIV_score', 'Polyphen2_HVAR_score', 'LRT_score', 'MutationTaster_score', 'MutationAssessor_score', 'FATHMM_score', 'RadialSVM_score', 'LR_score', 'VEST3_score', 'CADD_phred']\r\n",
    "# 原始数据文件目录\r\n",
    "raw_data_dir = '../data/variant/grimm_annovar_annotated'\r\n",
    "flitered_data_output_dir = '../data/filter'\r\n",
    "if not os.path.exists(flitered_data_output_dir):\r\n",
    "    os.mkdir(flitered_data_output_dir)\r\n",
    "# 合法染色体\r\n",
    "chrs = []\r\n",
    "for i in range(1, 23):\r\n",
    "    chrs.append(str(i))\r\n",
    "chrs.append(\"X\")\r\n",
    "chrs.append(\"Y\")\r\n",
    "\r\n",
    "\r\n",
    "# 从转录本提取氨基酸突变。eg LOXL4:NM_032211:exon3:c.C406A:p.R136S， aa_ref为R， aa_alt为S\r\n",
    "def split_transcript(row):\r\n",
    "    trans = row[\"AAChange.refGene\"]\r\n",
    "    trans = trans.split(\",\")\r\n",
    "    # first\r\n",
    "    tran = trans[0]\r\n",
    "    aachange = tran.split(\":\")\r\n",
    "    _ = aachange[-1].split(\".\")[-1]\r\n",
    "    aa_ref = _[0]\r\n",
    "    aa_alt = _[-1]\r\n",
    "    return aa_ref, aa_alt\r\n",
    "\r\n",
    "\r\n",
    "for dir_, _, filenames in os.walk(raw_data_dir):\r\n",
    "    for filename in filenames:\r\n",
    "        print(\"processing {}\".format(filename))\r\n",
    "        df = pd.read_csv(os.path.join(raw_data_dir, filename))\r\n",
    "        # df = df[features]\r\n",
    "        # .置空\r\n",
    "        df = df[~(df == '.')]\r\n",
    "        # # 剔除非法染色体\r\n",
    "        df[\"Chr\"] = df[\"Chr\"].astype(\"str\")\r\n",
    "        if filename == \"predictSNPSelected.hg19_multianno.csv\" or filename == \"SwissVarSelected.hg19_multianno.csv\":\r\n",
    "            df[[\"Chr\"]] = df.apply(lambda x: x[\"Chr\"][3:], axis=1)\r\n",
    "        df = df[(df[\"Chr\"].isin(chrs))]\r\n",
    "        # 处理氨基酸突变序列\r\n",
    "        df = df[~(df[\"AAChange.refGene\"].isnull())]\r\n",
    "        df[[\"A_Ref\", \"A_Alt\"]] = df.apply(split_transcript, axis=1, result_type=\"expand\")\r\n",
    "        df = df.drop([\"AAChange.refGene\"], axis=1)\r\n",
    "        # 类型转换\r\n",
    "        df = df.astype(dtype={'True Label': object, \"SIFT_score\": float, \"Polyphen2_HDIV_score\": float, \"Polyphen2_HVAR_score\": float, \"LRT_score\": float, \"MutationTaster_score\":float, \"MutationAssessor_score\": float, \"FATHMM_score\":float, \"RadialSVM_score\":float, \"LR_score\": float, \"VEST3_score\":float, \"CADD_phred\":float})\r\n",
    "        df[['Chr_', 'A_Ref_', 'A_Alt_']] = df.apply(encode, axis=1, result_type='expand')\r\n",
    "        df[\"True Label\"].replace(-1, 0, inplace=True)\r\n",
    "        df.to_csv(os.path.join(flitered_data_output_dir, \"{}\".format(filename)), index=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "save processed data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 去重\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "dfs = {}\r\n",
    "input_dir = \"../data/filter\"\r\n",
    "for root, _, files in os.walk(input_dir):\r\n",
    "    for file_ in files:\r\n",
    "        dataset = file_.split(\".\")[0]\r\n",
    "        df = pd.read_csv(os.path.join(root, file_))\r\n",
    "        dfs[dataset] = df\r\n",
    "\r\n",
    "datasets = ['ExoVarFiltered', 'HumVarFiltered', 'predictSNPSelected', 'SwissVarSelected', 'VariBenchSelected']\r\n",
    "df = pd.concat([dfs['HumVarFiltered'], dfs['predictSNPSelected'], dfs['VariBenchSelected']])\r\n",
    "df.drop_duplicates(subset=['Chr', 'Start', 'End', 'Ref', 'Alt'], inplace=True)\r\n",
    "\r\n",
    "df.to_csv('../data/dataset/training.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}